{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:10:03.580519Z",
     "start_time": "2025-07-30T13:10:03.558327Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abad316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir('/Users/weronikadorociak/Documents/LSE/MY498 Capstone Project/ai_aging')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaf6735a02dac5af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:10:04.381488Z",
     "start_time": "2025-07-30T13:10:03.586003Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Load data ---\n",
    "eurostat = pd.read_csv(\"original_data/eurostat.csv\")\n",
    "anthropic_df = pd.read_csv(\"original_data/anthropic.csv\")\n",
    "nace = pd.read_csv(\"transformed_data/economic_activity_sector.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2860a0a3fef9473a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:10:04.842922Z",
     "start_time": "2025-07-30T13:10:04.806106Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Extract unique economic activities (NACE codes) ---\n",
    "economic_activities = eurostat[\"nace_r2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e9d5faa9e3f8241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:10:04.883235Z",
     "start_time": "2025-07-30T13:10:04.881478Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Define sentence embedding models to compare ---\n",
    "models = [\n",
    "    \"all-MiniLM-L6-v2\",\n",
    "    \"all-mpnet-base-v2\",\n",
    "    \"paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    \"sentence-transformers/bert-base-nli-mean-tokens\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92225dbaa98611ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:10:28.053476Z",
     "start_time": "2025-07-30T13:10:04.920592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: all-MiniLM-L6-v2\n",
      "Processing model: all-mpnet-base-v2\n",
      "Processing model: paraphrase-multilingual-MiniLM-L12-v2\n",
      "Processing model: sentence-transformers/bert-base-nli-mean-tokens\n"
     ]
    }
   ],
   "source": [
    "# --- Initialize list to store similarity matching results ---\n",
    "records = []\n",
    "\n",
    "# --- Loop through each embedding model ---\n",
    "for model_name in models:\n",
    "    print(f\"Processing model: {model_name}\")\n",
    "    \n",
    "    # Load SentenceTransformer model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Encode task names and economic activity labels\n",
    "    task_emb = model.encode(anthropic_df['task_name'].tolist(), convert_to_tensor=True)\n",
    "    econ_emb = model.encode(economic_activities.tolist(), convert_to_tensor=True)\n",
    "    \n",
    "    # Compute cosine similarity between all tasks and all economic activities\n",
    "    sims = cosine_similarity(task_emb.cpu().numpy(), econ_emb.cpu().numpy())\n",
    "    \n",
    "    # Get index of the best matching economic activity for each task\n",
    "    best_idx = sims.argmax(axis=1)\n",
    "    \n",
    "    # Store the best match per task along with the model name and percentage\n",
    "    for i, task in enumerate(anthropic_df['task_name']):\n",
    "        rec = {\n",
    "            'task_name': task,\n",
    "            model_name: economic_activities[best_idx[i]],\n",
    "            'pct': anthropic_df.loc[i, 'pct']\n",
    "        }\n",
    "        records.append(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5237d0b51ef025",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:10:28.108055Z",
     "start_time": "2025-07-30T13:10:28.094592Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Convert raw records into a DataFrame ---\n",
    "df_long = pd.DataFrame(records)\n",
    "\n",
    "# --- Extract model-specific predictions (excluding nulls) ---\n",
    "all_MiniLM_L6_v2 = df_long[df_long['all-MiniLM-L6-v2'].notnull()][['task_name', 'pct', 'all-MiniLM-L6-v2']]\n",
    "all_mpnet_base_v2 = df_long[df_long['all-mpnet-base-v2'].notnull()][['task_name', 'pct', 'all-mpnet-base-v2']]\n",
    "MiniLM_L12_v2 = df_long[df_long['paraphrase-multilingual-MiniLM-L12-v2'].notnull()][['task_name', 'pct', 'paraphrase-multilingual-MiniLM-L12-v2']]\n",
    "bert = df_long[df_long['sentence-transformers/bert-base-nli-mean-tokens'].notnull()][['task_name', 'pct', 'sentence-transformers/bert-base-nli-mean-tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "269eb054d5907e5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:10:28.585795Z",
     "start_time": "2025-07-30T13:10:28.139666Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Merge all predictions into one DataFrame ---\n",
    "df_full = (\n",
    "    all_MiniLM_L6_v2\n",
    "    .merge(all_mpnet_base_v2, on=['task_name', 'pct'])\n",
    "    .merge(MiniLM_L12_v2, on=['task_name', 'pct'])\n",
    "    .merge(bert, on=['task_name', 'pct'])\n",
    ")\n",
    "\n",
    "# --- Count model agreement (how many models agree on the same category) ---\n",
    "model_cols = [\n",
    "    'all-MiniLM-L6-v2',\n",
    "    'all-mpnet-base-v2',\n",
    "    'paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    'sentence-transformers/bert-base-nli-mean-tokens'\n",
    "]\n",
    "\n",
    "def count_model_agreement(row):\n",
    "    return row[model_cols].value_counts().max()\n",
    "\n",
    "df_full['num_models_agree'] = df_full.apply(count_model_agreement, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80d968f2b61f5415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:10:29.104986Z",
     "start_time": "2025-07-30T13:10:28.628055Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Load ChatGPT fallback predictions ---\n",
    "chatgpt = pd.read_excel(\"transformed_data/gen_ai_adoption_model_disagremment_chatgpt.xlsx\")\n",
    "chatgpt.columns = [\"task_name\", \"chat_gpt_4o\"]\n",
    "\n",
    "# --- Merge ChatGPT predictions with model predictions ---\n",
    "df = df_full.merge(chatgpt, on='task_name', how='outer')\n",
    "\n",
    "# --- Define final prediction rule ---\n",
    "def choose_final_prediction(row):\n",
    "    if row['num_models_agree'] == 1:\n",
    "        return row['chat_gpt_4o']  # Low agreement → use GPT fallback\n",
    "    else:\n",
    "        votes = row[model_cols].dropna().value_counts()\n",
    "        if not votes.empty:\n",
    "            return votes.idxmax()  # Majority vote\n",
    "        else:\n",
    "            return row['chat_gpt_4o']  # All null → fallback again\n",
    "\n",
    "df['economic_activity_eurostat'] = df.apply(choose_final_prediction, axis=1)\n",
    "\n",
    "# --- Remove rows with missing 'pct' (no participation % data) ---\n",
    "df = df.dropna(subset=['pct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "533f7b376b3b41cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:10:29.162372Z",
     "start_time": "2025-07-30T13:10:29.155487Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Merge final predictions with NACE data to get sector names ---\n",
    "ai_adoption = df.merge(nace, how='left', left_on='economic_activity_eurostat', right_on='Economic Activity')\n",
    "\n",
    "# --- Aggregate AI adoption percentage by sector ---\n",
    "ai_adoption = ai_adoption.groupby(\"sector\")[\"pct\"].sum().reset_index()\n",
    "ai_adoption.columns = [\"sector\", \"ai_adoption\"]\n",
    "\n",
    "# --- Save results to CSV ---\n",
    "ai_adoption.to_csv(\"transformed_data/ai_adoption_sector.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
