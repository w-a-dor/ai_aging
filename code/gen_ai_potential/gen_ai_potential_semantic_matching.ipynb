{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:17:52.247690Z",
     "start_time": "2025-07-30T13:17:48.546601Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bd22afab496abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data ---\n",
    "eurostat = pd.read_csv('original_data/eurostat.csv')\n",
    "gpts_df = pd.read_csv('original_data/gpts_are_gpts.csv')\n",
    "nace = pd.read_csv('transformed_data/economic_activity_sector.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5051c371fdd1c86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:18:26.547499Z",
     "start_time": "2025-07-30T13:18:26.526772Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Prepare economic activity categories ---\n",
    "economic_activities = eurostat[\"nace_r2\"].unique()\n",
    "\n",
    "# --- Define sentence embedding models to compare ---\n",
    "models = [\n",
    "    \"all-MiniLM-L6-v2\",\n",
    "    \"all-mpnet-base-v2\",\n",
    "    \"paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    \"sentence-transformers/bert-base-nli-mean-tokens\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0823d032fdf176",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:18:21.899089Z",
     "start_time": "2025-07-30T13:18:21.797961Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Initialize list to store similarity matching results ---\n",
    "records = []\n",
    "\n",
    "# --- Loop through each embedding model ---\n",
    "for model_name in models:\n",
    "    print(f\"Processing model: {model_name}\")\n",
    "    \n",
    "    # Load SentenceTransformer model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Encode task names and economic activity labels\n",
    "    task_emb = model.encode(gpts_df['Title'].tolist(), convert_to_tensor=True)\n",
    "    econ_emb = model.encode(economic_activities.tolist(), convert_to_tensor=True)\n",
    "    \n",
    "    # Compute cosine similarity between all tasks and all economic activities\n",
    "    sims = cosine_similarity(task_emb.cpu().numpy(), econ_emb.cpu().numpy())\n",
    "    \n",
    "    # Get index of the best matching economic activity for each task\n",
    "    best_idx = sims.argmax(axis=1)\n",
    "    \n",
    "    # Store the best match per task along with the model name and percentage\n",
    "    for i, task in enumerate(gpts_df['Title']):\n",
    "        rec = {\n",
    "            'Title': task,\n",
    "            model_name: economic_activities[best_idx[i]],\n",
    "            'human_beta': gpts_df.loc[i, 'human_beta']\n",
    "        }\n",
    "        records.append(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f54048903f87f95f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:18:43.152451Z",
     "start_time": "2025-07-30T13:18:43.118693Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Convert raw records into a DataFrame ---\n",
    "df_long = pd.DataFrame(records)\n",
    "\n",
    "# --- Extract model-specific predictions (excluding nulls) ---\n",
    "all_MiniLM_L6_v2 = df_long[df_long['all-MiniLM-L6-v2'].notnull()][['Title', 'human_beta', 'all-MiniLM-L6-v2']]\n",
    "all_mpnet_base_v2 = df_long[df_long['all-mpnet-base-v2'].notnull()][['Title', 'human_beta', 'all-mpnet-base-v2']]\n",
    "MiniLM_L12_v2 = df_long[df_long['paraphrase-multilingual-MiniLM-L12-v2'].notnull()][['Title', 'human_beta', 'paraphrase-multilingual-MiniLM-L12-v2']]\n",
    "bert = df_long[df_long['sentence-transformers/bert-base-nli-mean-tokens'].notnull()][['Title', 'human_beta', 'sentence-transformers/bert-base-nli-mean-tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb155fade86f13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Merge all predictions into one DataFrame ---\n",
    "df_full = (\n",
    "    all_MiniLM_L6_v2\n",
    "    .merge(all_mpnet_base_v2, on=['Title', 'human_beta'])\n",
    "    .merge(MiniLM_L12_v2, on=['Title', 'human_beta'])\n",
    "    .merge(bert, on=['Title', 'human_beta'])\n",
    ")\n",
    "\n",
    "# --- Count model agreement (how many models agree on the same category) ---\n",
    "model_cols = [\n",
    "    'all-MiniLM-L6-v2',\n",
    "    'all-mpnet-base-v2',\n",
    "    'paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    'sentence-transformers/bert-base-nli-mean-tokens'\n",
    "]\n",
    "\n",
    "def count_model_agreement(row):\n",
    "    return row[model_cols].value_counts().max()\n",
    "\n",
    "df_full['num_models_agree'] = df_full.apply(count_model_agreement, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb41a05fde40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load ChatGPT fallback predictions for disagreement cases ---\n",
    "chatgpt = pd.read_excel(\"transformed_data/gen_ai_potential_model_disagremment_chatgpt.xlsx\")\n",
    "chatgpt.columns = [\"Title\", \"chat_gpt_4o\"]\n",
    "\n",
    "# --- Merge ChatGPT predictions with model predictions ---\n",
    "df = df_full.merge(chatgpt, on='Title', how='outer')\n",
    "\n",
    "# --- Define final prediction rule ---\n",
    "def choose_final_prediction(row):\n",
    "    if row['num_models_agree'] == 1:\n",
    "        return row['chat_gpt_4o']  # Low agreement → use GPT fallback\n",
    "    else:\n",
    "        votes = row[model_cols].dropna().value_counts()\n",
    "        if not votes.empty:\n",
    "            return votes.idxmax()  # Majority vote\n",
    "        else:\n",
    "            return row['chat_gpt_4o']  # All null → fallback again\n",
    "\n",
    "df['economic_activity_eurostat'] = df.apply(choose_final_prediction, axis=1)\n",
    "\n",
    "# --- Remove rows with missing 'pct' (no participation % data) ---\n",
    "df = df.dropna(subset=['human_beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c1a92f02f6baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Merge with NACE sector info and calculate mean AI potential ---\n",
    "ai_potential = df.merge(nace, how='left', left_on='economic_activity_eurostat', right_on='Economic Activity')\n",
    "ai_potential = ai_potential.groupby(\"sector\")[\"human_beta\"].mean().reset_index()\n",
    "ai_potential[\"human_beta\"] = ai_potential[\"human_beta\"] * 100  # Convert to percentage\n",
    "ai_potential.columns = [\"sector\", \"ai_potential\"]\n",
    "\n",
    "# --- Export result to CSV ---\n",
    "ai_potential.to_csv(\"transformed_data/ai_potential_sector.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
